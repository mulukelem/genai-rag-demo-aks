
# RAG PDF Chatbot

This project demonstrates a Retrieval-Augmented Generation (RAG) chatbot using a local LLaMA model deployed on Azure Kubernetes Service (AKS).

## ğŸ§± Project Structure

```
rag-pdf-chatbot/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Jenkinsfile
â”œâ”€â”€ models/
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ pv.yaml
â”‚   â””â”€â”€ pvc.yaml
â””â”€â”€ README.md
```

## ğŸš€ Prerequisites
- Azure CLI & logged in
- AKS cluster
- Azure Container Registry (ACR)
- Jenkins server with necessary Azure CLI and Docker installed

## ğŸ” Jenkins Pipeline Steps

1. Build and push Docker image to ACR
2. Provision AKS credentials
3. Apply Kubernetes manifests for persistent volume and deployment

## ğŸ”„ Model Volume

Make sure your LLaMA model is available on your AKS node at `/mnt/models/llama`.
